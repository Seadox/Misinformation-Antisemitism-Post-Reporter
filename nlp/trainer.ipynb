{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee96080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "53f3d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Index(['hate_speech_count', 'tweet'], dtype='object') ,  (718757, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"output_filtered.csv\")\n",
    "print(\"Training set\", train.columns, \", \", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "625ce1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(data_frame, field):\n",
    "    data_frame[field] = data_frame[field].str.lower()\n",
    "    data_frame[field] = data_frame[field].apply(lambda x:re.sub(r\"(@[\\w]+)|([^0-9A-z \\t])|(\\w+:\\/\\/\\s+)|^rt|http.+?\", '', x))\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aa79c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        hate_speech_count                                              tweet\n",
      "0                       0   rt  as a woman you shouldnt complain about cl...\n",
      "1                       0   rt  boy dats coldtyga dwn bad for cuffin dat ...\n",
      "2                       0   rt  dawg rt  you ever fuck a bitch and she st...\n",
      "3                       0                        rt   she look like a tranny\n",
      "4                       0   rt  the shit you hear about me might be true ...\n",
      "...                   ...                                                ...\n",
      "718752                  1  i mute this telecasting and played kanye west ...\n",
      "718753                  1  but hell yeah he s not a bachelor but looooooo...\n",
      "718754                  1  great video musician but s not my musician lol...\n",
      "718755                  1  not great pop video yeah he s not a pedophile ...\n",
      "718756                  1  great video yeah he s non a paedophile lolllll...\n",
      "\n",
      "[718757 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train = preproc(train, 'tweet')\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f0f14639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_maj = train[train.hate_speech_count == 0]\n",
    "train_min = train[train.hate_speech_count == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c72c429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    372654\n",
      "1    372654\n",
      "Name: hate_speech_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_min_upsampled = resample(train_min, replace=True, n_samples=len(train_maj), random_state = 99)\n",
    "train_subsampled = pd.concat([train_min_upsampled, train_maj])\n",
    "print(train_subsampled['hate_speech_count'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "93ab0632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.90597991970519\n"
     ]
    }
   ],
   "source": [
    "SGD = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('nb', SGDClassifier())])\n",
    "x_train, X_test, Y_train, Y_test = train_test_split(train_subsampled['tweet'], train_subsampled['hate_speech_count'], random_state=42,test_size=0.2)\n",
    "\n",
    "model = SGD.fit(x_train, Y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "444c452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is hate_speech:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is hate_speech: \",bool(model.predict([\"\"\"\n",
    "Because sometimes, against all the odds, we keep the faith, and hope! \n",
    "\n",
    "We don't care which political party is doing what publicity. We don't want to waste our energy on the people who're 'NOT' speaking up. We would rather give our energy where it is needed   to unite with anyone who is standing up for the seen truth. The truth of evil. The truth of human rights violation. The truth of islamophobia. The truth of   being jer* and the truth of people of g@z@.\n",
    "\n",
    "We will show  solidarity because we know they need us. They need to be heard. And our voices will reach out to them. Our voices are the weapons for them. \n",
    "\n",
    "What can we do more? \n",
    "We will keep posting. We will put pressure on the authorities for ceasefire. We want genocide to stop. We will donate, we will learn the history. We will educate ourselves and others. And most importantly, we will pray for them! It's high time. It's high time for us to unite for  \n",
    "\n",
    "Prayers and love for p@lest!n3 and its people, always and forever!  \n",
    "\"\"\"])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "00054404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1fcc2d1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benGvir_NLP_filtered.joblib']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'benGvir_NLP_filtered.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2884d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('benGvir_NLP_filtered.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "119fc926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the new text: [0]\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"en passant\"]\n",
    "\n",
    "new_text_predictions = loaded_model.predict(new_text)\n",
    "\n",
    "print(f'Predictions for the new text: {new_text_predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceeb3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
